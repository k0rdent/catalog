tags:
  - AI/Machine Learning
title: "Open WebUI"
summary: "A User-Friendly Web Interface for Chat Interactions."
logo: "https://raw.githubusercontent.com/open-webui/open-webui/main/static/favicon.png"
created: "2025-03-12T08:16:55Z"
description: |
    Open WebUI is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline.
    It supports various LLM runners like Ollama and OpenAI-compatible APIs, with built-in inference engine for RAG, making it
    a powerful AI deployment solution.

    <div>
    ![](https://docs.openwebui.com/assets/images/demo-d3952c8561c4808c1d447fc061c71174.gif){ width="700" }
    </div>
charts:
  - name: open-webui
    versions: ['8.10.0', '6.20.0']
deploy_code: |
    ##### Configuration without GPU
    Tested on worker `instanceType: t3.xlarge` and `rootVolumeSize: 32`:
    ~~~yaml
    apiVersion: k0rdent.mirantis.com/v1beta1
    kind: ClusterDeployment
    metadata:
      name: aws-example
    spec:
      template: {{ aws_standalone_cp }}
      credential: aws-credential
      config:
        ...
        worker:
          instanceType: t3.xlarge
          rootVolumeSize: 32
        workersNumber: 1
    ~~~

    Tested service configuration:
    ~~~yaml
    apiVersion: k0rdent.mirantis.com/v1beta1
    kind: MultiClusterService
    metadata:
      name: open-webui
    spec:
      clusterSelector:
        matchLabels:
          group: demo
      serviceSpec:
        services:
        - template: open-webui-8-10-0
          name: open-webui
          namespace: open-webui
          values: |
            open-webui:
              ollama:
                ollama:
                  models:
                    pull: [smollm:135m]
                    run: [smollm:135m]
              ingress:
                enabled: true
                class: "nginx"
                host: 'openwebui.example.com'
    ~~~

    ##### Configuration with GPU
    This setup requires corresponding cluster setup, see [NVIDIA GPU Operator](../../../{{ version }}/apps/nvidia/#install){ target="_blank" }

    ~~~yaml
    apiVersion: k0rdent.mirantis.com/v1beta1
    kind: MultiClusterService
    metadata:
      name: open-webui
    spec:
      clusterSelector:
        matchLabels:
          group: demo
      serviceSpec:
        services:
        - template: open-webui-8-10-0
          name: open-webui
          namespace: open-webui
          values: |
            open-webui:
              ollama:
                ollama:
                  gpu:
                    enabled: true
                    type: 'nvidia'
                    number: 1
                  models:
                    pull: [llama3.2:3b]
                    run: [llama3.2:3b]
              ingress:
                enabled: true
                class: "nginx"
                host: 'openwebui.example.com'
    ~~~
doc_link: https://docs.openwebui.com/
use_ingress: true

# test settings
test_deploy_chart: false # only deploy mcs to save time and resources - big deployment
