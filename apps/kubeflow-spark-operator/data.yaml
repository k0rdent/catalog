tags:
  - AI/Machine Learning
title: "Kubeflow Spark Operator"
summary: "The Kubernetes Operator for Apache Spark."
logo: "./assets/icon.svg" # https://github.com/kubeflow/kubeflow/blob/master/logo/icon.svg
logo_big: "./assets/logo.svg" # https://github.com/kubeflow/kubeflow/blob/master/logo/horizontal.svg
created: "2025-09-29T17:51:52Z"
description: |
  ## What is Spark Operator?

  The Kubernetes Operator for Apache Spark aims to make specifying and
  running [Spark](https://github.com/apache/spark) applications as easy and idiomatic
  as running other workloads on Kubernetes. It uses

  [Kubernetes custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)
  for specifying, running, and surfacing status of Spark applications.

  ## Overview
  For a complete reference of the custom resource definitions, please refer to the [API Definition](docs/api-docs.md). For details on its design, please refer to the [Architecture](https://www.kubeflow.org/docs/components/spark-operator/overview/#architecture). It requires Spark 2.3 and above that supports Kubernetes as a native scheduler backend.

  The Kubernetes Operator for Apache Spark currently supports the following list of features:

  - Supports Spark 2.3 and up.
  - Enables declarative application specification and management of applications through custom resources.
  - Automatically runs `spark-submit` on behalf of users for each `SparkApplication` eligible for submission.
  - Provides native [cron](https://en.wikipedia.org/wiki/Cron) support for running scheduled applications.
  - Supports customization of Spark pods beyond what Spark natively is able to do through the mutating admission webhook, e.g., mounting ConfigMaps and volumes, and setting pod affinity/anti-affinity.
  - Supports automatic application re-submission for updated `SparkApplication` objects with updated specification.
  - Supports automatic application restart with a configurable restart policy.
  - Supports automatic retries of failed submissions with optional linear back-off.
  - Supports collecting and exporting application-level metrics and driver/executor metrics to Prometheus.
# support_link: TODO
charts:
  - name: kubeflow-spark-operator
    versions: ['2.3.0']
deploy_code: |
  ~~~yaml
  apiVersion: k0rdent.mirantis.com/v1beta1
  kind: MultiClusterService
  metadata:
    name: kubeflow-spark-operator
  spec:
    clusterSelector:
      matchLabels:
        group: demo
    serviceSpec:
      services:
      - template: kubeflow-spark-operator-2-3-0
        name: kubeflow-spark-operator
        namespace: kubeflow-spark-operator
        values: |
          spark-operator:
            controller:
              uiIngress:
                enable: true
                ingressClassName: nginx
  ~~~
doc_link: https://github.com/kubeflow/spark-operator

test_wait_for_pods: "kubeflow-spark-operator-controller-"

validated_amd64: 'y'
validated_aws: 'y'
validated_azure: 'y'
validated_arm64: '-'
